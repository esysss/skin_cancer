{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dARJIbbzcDiP"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rDqqH2-usSgD"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/content/drive/MyDrive/choosen/train.pkl')\n",
    "test_data = pd.read_pickle('/content/drive/MyDrive/choosen/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yaCFqToSc5JL",
    "outputId": "b7847cd0-7c01-465b-94e8-9f886aaa0d40"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTrainin = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(train_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTrainin.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTesting = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(test_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTesting.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "print(\"Image resizing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C-RerqHsdEPb"
   },
   "outputs": [],
   "source": [
    "labels_one_hot = train_data.iloc[:, 1:].values\n",
    "labelstrain = [list(row).index(1.0) for row in labels_one_hot]\n",
    "labels_one_hot = test_data.iloc[:, 1:].values\n",
    "labelstest = [list(row).index(1.0) for row in labels_one_hot]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B5sbmXsueVYk"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "stacked_array = np.stack(labelstrain)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_train = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(labelstest)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_test = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(imgsTrainin)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_train = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor\n",
    "\n",
    "stacked_array = np.stack(imgsTesting)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_test = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ucgLpJTfkbM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Example data (replace with your actual tensors)\n",
    "train_images = torch_images_train.permute(0, 3, 1, 2)\n",
    "test_images = torch_images_test.permute(0, 3, 1, 2)\n",
    "train_labels = torch_labels_train\n",
    "test_labels = torch_labels_test\n",
    "\n",
    "# Wrap into TensorDataset\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "05YUdjNPgLJb",
    "outputId": "f02ae6c5-1f3a-4261-f678-b2c573fc5568"
   },
   "outputs": [],
   "source": [
    "# Define the CNN Model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes=8):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.flattened_size = None  # Placeholder to calculate the size dynamically\n",
    "        self.fc1 = None\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        if self.flattened_size is None:\n",
    "            # Calculate flattened size dynamically\n",
    "            self.flattened_size = torch.prod(torch.tensor(x.shape[1:])).item()\n",
    "            self.fc1 = nn.Linear(self.flattened_size, 256).to(x.device)\n",
    "\n",
    "        x = x.view(x.size(0), -1)  # Flatten\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = SimpleCNN(num_classes=8).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "trainingHolder = []\n",
    "testingHolder = []\n",
    "\n",
    "num_epochs = 40\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "    # Testing loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "    testingHolder.append(100 * correct / total)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    trainingHolder.append(100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W5QgZn6HQgD"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  model = SimpleCNN(num_classes=8).to(device)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  # Training loop\n",
    "  trainingHolder = []\n",
    "  testingHolder = []\n",
    "\n",
    "  num_epochs = 40\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "\n",
    "      for images, labels in train_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # Backward pass and optimization\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "\n",
    "      # print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "      # Testing loop\n",
    "      model.eval()\n",
    "      correct = 0\n",
    "      total = 0\n",
    "\n",
    "      with torch.no_grad():\n",
    "          for images, labels in test_loader:\n",
    "              images, labels = images.to(device), labels.to(device)\n",
    "              outputs = model(images)\n",
    "              _, predicted = torch.max(outputs.data, 1)\n",
    "              total += labels.size(0)\n",
    "              correct += (predicted == labels).sum().item()\n",
    "\n",
    "      # print(f'Test Accuracy: {100 * correct / total:.2f}%')\n",
    "      testingHolder.append(100 * correct / total)\n",
    "\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      with torch.no_grad():\n",
    "          for images, labels in train_loader:\n",
    "              images, labels = images.to(device), labels.to(device)\n",
    "              outputs = model(images)\n",
    "              _, predicted = torch.max(outputs.data, 1)\n",
    "              total += labels.size(0)\n",
    "              correct += (predicted == labels).sum().item()\n",
    "\n",
    "      trainingHolder.append(100 * correct / total)\n",
    "  return max(testingHolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UJItVa36HirL",
    "outputId": "c41de0ed-67eb-43fb-d292-69235ab8c4a8"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "acc = []\n",
    "for i in tqdm(range(10)):\n",
    "  acc.append(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "3Fp2IJxNgrkL",
    "outputId": "00ae3879-9b69-4491-ce3f-100329a22f0d"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(trainingHolder) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, trainingHolder, label='Training Accuracy', marker='o', color='blue')\n",
    "plt.plot(epochs, testingHolder, label='Testing Accuracy', marker='s', color='orange')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NqQqVpDNgtCb",
    "outputId": "c1da5637-cb1a-4c07-d45c-b5b1e2fc83ea"
   },
   "outputs": [],
   "source": [
    "testingHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p3ft2_Slrcp6",
    "outputId": "99825784-8fd3-4c63-9e7d-c4d06886e633"
   },
   "outputs": [],
   "source": [
    "max(testingHolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "76lpsc6W4CZG",
    "outputId": "6a5c4960-6777-481b-951e-fb4bfeb5955c"
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIGB-HW6IyCC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
