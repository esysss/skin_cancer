{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3Lfqhf7ZrO2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9QjY4QAchx4"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/content/drive/MyDrive/choosen/train.pkl')\n",
    "test_data = pd.read_pickle('/content/drive/MyDrive/choosen/test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F7Jpom6IcmWu",
    "outputId": "c1c6558f-df15-4f06-ed29-2ec800660cc8"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTrainin = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(train_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTrainin.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTesting = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(test_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTesting.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "print(\"Image resizing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F6WLgBMOcowe"
   },
   "outputs": [],
   "source": [
    "labels_one_hot = train_data.iloc[:, 1:].values\n",
    "labelstrain = [list(row).index(1.0) for row in labels_one_hot]\n",
    "labels_one_hot = test_data.iloc[:, 1:].values\n",
    "labelstest = [list(row).index(1.0) for row in labels_one_hot]\n",
    "\n",
    "stacked_array = np.stack(labelstrain)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_train = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(labelstest)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_test = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(imgsTrainin)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_train = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor\n",
    "\n",
    "stacked_array = np.stack(imgsTesting)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_test = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TL7l1SvYjmaf"
   },
   "outputs": [],
   "source": [
    "# Example data (replace with your actual tensors)\n",
    "train_images = torch_images_train.permute(0, 3, 1, 2)\n",
    "test_images = torch_images_test.permute(0, 3, 1, 2)\n",
    "train_labels = torch_labels_train\n",
    "test_labels = torch_labels_test\n",
    "\n",
    "# Wrap into TensorDataset\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1EbRy7pbjpOv"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "# Normalize the dataset using ImageNet's mean and standard deviation\n",
    "imagenet_normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_images = imagenet_normalize(train_images)\n",
    "test_images = imagenet_normalize(test_images)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# Load the pretrained VGG-16 model\n",
    "model = vgg19(pretrained=True)\n",
    "\n",
    "# Modify the classifier to match your dataset's number of classes\n",
    "num_classes = len(torch.unique(train_labels))  # Adjust based on your dataset\n",
    "model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "# Move the model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3hC7Emt7mMzm"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "id": "BpGm5-4omQr3",
    "outputId": "fd5f3705-9fe0-4a39-f4cd-60a5053fccab"
   },
   "outputs": [],
   "source": [
    "# Training loop\n",
    "trainingHolder = []\n",
    "testingHolder = []\n",
    "\n",
    "epochs = 40  # Adjust the number of epochs as needed\n",
    "for epoch in range(epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  for images, labels in train_loader:\n",
    "      images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(images)\n",
    "      loss = criterion(outputs, labels)\n",
    "\n",
    "      # Backward pass and optimization\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      running_loss += loss.item()\n",
    "\n",
    "    # Evaluation loop\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in test_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  testingHolder.append(100 * correct / total)\n",
    "\n",
    "  model.eval()\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  with torch.no_grad():\n",
    "      for images, labels in train_loader:\n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "          outputs = model(images)\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          total += labels.size(0)\n",
    "          correct += (predicted == labels).sum().item()\n",
    "\n",
    "  trainingHolder.append(100 * correct / total)\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R7_A97OcQEpz"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "def test():\n",
    "  model = vgg19(pretrained=True)\n",
    "\n",
    "  # Modify the classifier to match your dataset's number of classes\n",
    "  num_classes = len(torch.unique(train_labels))  # Adjust based on your dataset\n",
    "  model.classifier[6] = nn.Linear(4096, num_classes)\n",
    "\n",
    "  # Move the model to GPU if available\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "  model = model.to(device)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "  # Training loop\n",
    "  trainingHolder = []\n",
    "  testingHolder = []\n",
    "\n",
    "  epochs = 40  # Adjust the number of epochs as needed\n",
    "  for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "      # Evaluation loop\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    testingHolder.append(100 * correct / total)\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    trainingHolder.append(100 * correct / total)\n",
    "\n",
    "    # print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")\n",
    "\n",
    "  return max(testingHolder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zVJrD5L9QW2r",
    "outputId": "4d08eb8a-5b6d-4860-f224-aff3f664554d"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "acc = []\n",
    "for i in tqdm(range(10)):\n",
    "  acc.append(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "Tj6b0PJsmS7W",
    "outputId": "59aeace2-1e54-48a5-ae43-1d88d6570692"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(trainingHolder) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, trainingHolder, label='Training Accuracy', marker='o', color='blue')\n",
    "plt.plot(epochs, testingHolder, label='Testing Accuracy', marker='s', color='orange')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N3rJ55-TrMRg",
    "outputId": "3c1a990c-4942-4c93-e51a-54fd304cc523"
   },
   "outputs": [],
   "source": [
    "testingHolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bxBpoobVrRve",
    "outputId": "a0fddce2-adc6-4bae-d164-12207cda4282"
   },
   "outputs": [],
   "source": [
    "max(testingHolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-1vBpsWt3jZe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
