{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dsHK4RjhdzG-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_qMVUsu5d8Rd"
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/content/drive/MyDrive/choosen/train.pkl')\n",
    "test_data = pd.read_pickle('/content/drive/MyDrive/choosen/test.pkl')\n",
    "\n",
    "train_metadata = pd.read_csv(\"/content/drive/MyDrive/choosen/train_metadata.csv\")\n",
    "test_metadata = pd.read_csv(\"/content/drive/MyDrive/choosen/test_metadata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eNgTAIZ7eVVO",
    "outputId": "36d12fc2-eb5a-416f-f948-3873b3a5e500"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTrainin = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(train_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTrainin.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "# Assuming `balanced_df` contains the image names in the 'image' column\n",
    "imgsTesting = []\n",
    "# Output directory for resized images\n",
    "\n",
    "# Loop through the image names in balanced_df and process them\n",
    "for image_name in tqdm(test_data['image']):\n",
    "    # Construct the full image file path\n",
    "    image_path = os.path.join(\"/content/drive/MyDrive/choosen/\" + image_name + \".jpg\")  # Adjust extension if needed\n",
    "\n",
    "    # Read the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    if image is None:\n",
    "        print(f\"Image {image_name} not found or could not be read.\")\n",
    "        continue\n",
    "\n",
    "    # Resize the image to 500x500\n",
    "    resized_image = cv2.resize(image, (224, 224))\n",
    "    imgsTesting.append(resized_image)\n",
    "\n",
    "    # Save the resized image to the output directory\n",
    "    # output_path = os.path.join(output_directory, image_name + \"_resized.jpg\")\n",
    "    # cv2.imwrite(output_path, resized_image)\n",
    "\n",
    "print(\"Image resizing completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRZIxb2ZeXM8"
   },
   "outputs": [],
   "source": [
    "labels_one_hot = train_data.iloc[:, 1:].values\n",
    "labelstrain = [list(row).index(1.0) for row in labels_one_hot]\n",
    "labels_one_hot = test_data.iloc[:, 1:].values\n",
    "labelstest = [list(row).index(1.0) for row in labels_one_hot]\n",
    "\n",
    "stacked_array = np.stack(labelstrain)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_train = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(labelstest)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_labels_test = torch.from_numpy(stacked_array)\n",
    "\n",
    "stacked_array = np.stack(imgsTrainin)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_train = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor\n",
    "\n",
    "stacked_array = np.stack(imgsTesting)  # Shape: (num_samples, 3, 500, 500)\n",
    "torch_images_test = torch.from_numpy(stacked_array).float()  # Ensure it's a float tensor\n",
    "\n",
    "# Example data (replace with your actual tensors)\n",
    "train_images = torch_images_train.permute(0, 3, 1, 2)\n",
    "test_images = torch_images_test.permute(0, 3, 1, 2)\n",
    "train_labels = torch_labels_train\n",
    "test_labels = torch_labels_test\n",
    "\n",
    "# Wrap into TensorDataset\n",
    "train_dataset = TensorDataset(train_images, train_labels)\n",
    "test_dataset = TensorDataset(test_images, test_labels)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2P5sJ3Kwk-tN"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import vgg19\n",
    "import torch.nn as nn\n",
    "from torchvision.transforms import Normalize\n",
    "\n",
    "X_train = train_metadata.drop(columns=['image'])  # Remove 'image' column if not used for training\n",
    "y_train = np.array(labelstrain)  # Assuming this is a list or array of labels\n",
    "\n",
    "X_test = test_metadata.drop(columns=['image'])  # Remove 'image' column if not used for training\n",
    "y_test = np.array(labelstest)  # Assuming this is a list or array of labels\n",
    "\n",
    "# Normalize/Standardize the data (especially for age and anatomical site)\n",
    "scaler = StandardScaler()\n",
    "X_scaled_train = scaler.fit_transform(X_train)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled_test = scaler.fit_transform(X_test)\n",
    "\n",
    "imagenet_normalize = Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "train_images = imagenet_normalize(train_images)\n",
    "test_images = imagenet_normalize(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i_ORV4JOlAzN",
    "outputId": "462ed876-3ea9-4f64-e143-74fce3d9a64e"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "\n",
    "# 1. Prepare the dataset combining images and metadata\n",
    "\n",
    "# Assuming X_scaled_train and X_scaled_test are metadata (scaled),\n",
    "# and train_images and test_images are your image tensors.\n",
    "\n",
    "# Load metadata\n",
    "X_train = torch.tensor(X_scaled_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_scaled_test, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "# Combine image data and metadata into one dataset\n",
    "class CombinedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images, metadata, labels):\n",
    "        self.images = images\n",
    "        self.metadata = metadata\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        meta = self.metadata[idx]\n",
    "        label = self.labels[idx]\n",
    "        return image, meta, label\n",
    "\n",
    "train_dataset = CombinedDataset(train_images, X_train, y_train)\n",
    "test_dataset = CombinedDataset(test_images, X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 2. Define the hybrid model (VGG16 + FC)\n",
    "\n",
    "class HybridVGG16FCModel(nn.Module):\n",
    "    def __init__(self, num_classes=8, metadata_dim=3):\n",
    "        super(HybridVGG16FCModel, self).__init__()\n",
    "\n",
    "        # Load pre-trained VGG16 model\n",
    "        vgg16 = models.vgg19(pretrained=True)\n",
    "\n",
    "        # Use VGG16 layers, but remove the fully connected layers (classifier)\n",
    "        self.features = vgg16.features\n",
    "\n",
    "        # Get the size of the output from the VGG16 feature extractor\n",
    "        with torch.no_grad():\n",
    "            dummy_input = torch.zeros(1, 3, 224, 224)  # VGG16 expects 224x224 images\n",
    "            cnn_output = self.features(dummy_input)\n",
    "            flattened_size = cnn_output.view(1, -1).size(1)  # Flatten the output\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        self.fc1 = nn.Linear(flattened_size + metadata_dim, 128)  # Input is CNN output + metadata\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.fc3 = nn.Linear(64, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, image, metadata):\n",
    "        # VGG16 feature extraction\n",
    "        x = self.features(image)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the output\n",
    "\n",
    "        # Concatenate CNN features with metadata\n",
    "        x = torch.cat((x, metadata), dim=1)\n",
    "\n",
    "        # Fully connected layers for classification\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # Output layer without softmax\n",
    "        return x  # No softmax here, as CrossEntropyLoss handles it internally\n",
    "\n",
    "\n",
    "# 3. Initialize the model, loss function, and optimizer\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = HybridVGG16FCModel(num_classes=8, metadata_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 4. Training and testing loop\n",
    "\n",
    "num_epochs = 40\n",
    "trainingHolder = []\n",
    "testingHolder = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "\n",
    "    for images, metadata, labels in train_loader:\n",
    "        images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images, metadata)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct_preds += (predicted == labels).sum().item()\n",
    "        total_preds += labels.size(0)\n",
    "\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    accuracy = (correct_preds / total_preds) * 100\n",
    "    trainingHolder.append(accuracy)\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    correct_preds = 0\n",
    "    total_preds = 0\n",
    "    with torch.no_grad():\n",
    "        for images, metadata, labels in test_loader:\n",
    "            images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "            outputs = model(images, metadata)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct_preds += (predicted == labels).sum().item()\n",
    "            total_preds += labels.size(0)\n",
    "\n",
    "    accuracy = (correct_preds / total_preds) * 100\n",
    "    testingHolder.append(accuracy)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Training Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wfDsilDRUPb"
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "  model = HybridVGG16FCModel(num_classes=8, metadata_dim=X_train.shape[1]).to(device)\n",
    "\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "  # 4. Training and testing loop\n",
    "\n",
    "  num_epochs = 40\n",
    "  trainingHolder = []\n",
    "  testingHolder = []\n",
    "\n",
    "  for epoch in range(num_epochs):\n",
    "      model.train()\n",
    "      running_loss = 0.0\n",
    "      correct_preds = 0\n",
    "      total_preds = 0\n",
    "\n",
    "      for images, metadata, labels in train_loader:\n",
    "          images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = model(images, metadata)\n",
    "          loss = criterion(outputs, labels)\n",
    "\n",
    "          # Backward pass and optimization\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "\n",
    "          running_loss += loss.item()\n",
    "          _, predicted = torch.max(outputs, 1)\n",
    "          correct_preds += (predicted == labels).sum().item()\n",
    "          total_preds += labels.size(0)\n",
    "\n",
    "      avg_loss = running_loss / len(train_loader)\n",
    "      accuracy = (correct_preds / total_preds) * 100\n",
    "      trainingHolder.append(accuracy)\n",
    "\n",
    "      # Validation loop\n",
    "      model.eval()\n",
    "      correct_preds = 0\n",
    "      total_preds = 0\n",
    "      with torch.no_grad():\n",
    "          for images, metadata, labels in test_loader:\n",
    "              images, metadata, labels = images.to(device), metadata.to(device), labels.to(device)\n",
    "              outputs = model(images, metadata)\n",
    "              _, predicted = torch.max(outputs, 1)\n",
    "              correct_preds += (predicted == labels).sum().item()\n",
    "              total_preds += labels.size(0)\n",
    "\n",
    "      accuracy = (correct_preds / total_preds) * 100\n",
    "      testingHolder.append(accuracy)\n",
    "\n",
    "      # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Training Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "  return(max(testingHolder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGV5H-plRUV0",
    "outputId": "75fb6e86-e58d-4ff2-958d-15b349d5a6a5"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "acc = []\n",
    "for i in tqdm(range(10)):\n",
    "  acc.append(test())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "MH8IB1EwlNgk",
    "outputId": "771a3647-83cb-465e-9045-6fcafa9af248"
   },
   "outputs": [],
   "source": [
    "epochs = range(1, len(trainingHolder) + 1)\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs, trainingHolder, label='Training Accuracy', marker='o', color='blue')\n",
    "plt.plot(epochs, testingHolder, label='Testing Accuracy', marker='s', color='orange')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training vs Testing Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5IUesTkFlU_M",
    "outputId": "847ab07f-9887-45d1-841b-b2b70b098428"
   },
   "outputs": [],
   "source": [
    "max(testingHolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9fGrqqePlWs0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
